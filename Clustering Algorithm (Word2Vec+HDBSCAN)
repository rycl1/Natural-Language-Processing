import spacy
from spacy.tokens import Doc
import numpy as np 
import nltk 
nltk.download('perluniprops')
from nltk.tokenize.moses import MosesDetokenizer
nltk.download('punkt')
nltk.download('stopwords')

import hdbscan
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.cluster as cluster
import time
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import pandas as pd
import codecs

nltk_stopwords = nltk.corpus.stopwords.words('english')

spacy.prefer_gpu()

nlp = spacy.load('en_core_web_lg')

f = open('requests.txt', encoding = "utf8")

z = f.readlines()

detokenizer = MosesDetokenizer()

datavecs = []

plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}

def plot_clusters(data, algorithm, args, kwds):
    start_time = time.time()
    labels = algorithm(*args, **kwds).fit_predict(data)
    end_time = time.time()
    palette = sns.color_palette('deep', np.unique(labels).max() + 1)
    colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]
    plt.scatter(data.T[0], data.T[1], c=colors, **plot_kwds)
    frame = plt.gca()
    frame.axes.get_xaxis().set_visible(False)
    frame.axes.get_yaxis().set_visible(False)
    plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=24)
    plt.text(-0.5, 0.7, 'Clustering took {:.2f} s'.format(end_time - start_time), fontsize=14)
    
for request in z:
    tokens = nltk.tokenize.word_tokenize(request)
    tokens = [token for token in tokens if not token in nltk_stopwords]
    real = detokenizer.detokenize(tokens, return_str=True)
    for sentence in real:
        doc = nlp(sentence)
        datavecs.append(doc.vector)

npa = np.asarray(datavecs, dtype=np.float32)

embedding = umap.UMAP().fit_transform(npa.data)

minclusters = 2

newclusterer4 = hdbscan.HDBSCAN(min_cluster_size=minclusters, min_samples=1, allow_single_cluster=False).fit(embedding)

print(newclusterer4.labels_)

testm2 = newclusterer4.labels_.tolist()
datanew2 = {'String':l,'Cluster':testm2}
df7new = pd.DataFrame(datanew2)


maxlabel = max(testm2)
label_range = list(range(-1, maxlabel + 1))
for clusnum in label_range:
    print(df7new.loc[df7new['Cluster'] == clusnum])
    
    
    
    
outputstring = "Your data produced" + " " + str(maxlabel) + " " + "clusters with a minimum of" + " " + str(minclusters) + " " + "phrases per cluster."

testm2 = newclusterer4.labels_.tolist()
testm3 = newclusterer4.probabilities_.tolist()
datanew2 = {'String':l,'Cluster':testm2,'Strength':testm3}
df7new = pd.DataFrame(datanew2)

df8new = pd.DataFrame(df7new.loc[df7new['Strength'] == 1])


df8new = df8new.drop_duplicates('Cluster')

print(outputstring)
print(df8new)
    
frame = df8new

def print_full(frame):
    pd.set_option('display.max_rows', len(frame))
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 2000)
    pd.set_option('display.float_format', '{:20,.2f}'.format)
    pd.set_option('display.max_colwidth', -1)
    print(frame)
    pd.reset_option('display.max_rows')
    pd.reset_option('display.max_columns')
    pd.reset_option('display.width')
    pd.reset_option('display.float_format')
    pd.reset_option('display.max_colwidth')


print_full(df8new)  
